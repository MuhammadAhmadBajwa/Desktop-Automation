{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3816f903-bc2d-494b-9246-118014e385de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start \n",
    "import pyautogui\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "import torch \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "# Load/save cache between sessions\n",
    "import json\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from icon_caption import load_resnet_model, load_yolo_model,load_florence_model,load_ocr,get_parsed_icons_captions\n",
    "\n",
    "\n",
    "\n",
    "def Capture_ScreenShot(screenshot_path=\"screenshot.png\"):\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    screenshot.save(screenshot_path)\n",
    "    return screenshot_path\n",
    "\n",
    "\n",
    "def LLM(api,user_prompt,model=\"llama-3.3-70b-versatile\",system_prompt=None,max_new_token=1024):\n",
    "    messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"{system_prompt}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{user_prompt}\"\n",
    "            },\n",
    "            ]            \n",
    "    completion = api.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_completion_tokens=max_new_token,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    json_match = re.search(r'\\{.*\\}',response,re.DOTALL)\n",
    "    if json_match:\n",
    "        json_string = json_match.group(0)\n",
    "        response = json.loads(json_string)\n",
    "        #print(\"Parsed JSON: \",json_data)\n",
    "    else:\n",
    "        print(\"No valid JSON found in the response\")\n",
    "        response = None\n",
    "    return response\n",
    "\n",
    "    \n",
    "def Icon_Selection(api,task,parsed_content_list):\n",
    "    system_prompt = f\"You are an excellent GUI Automation Bot that work on windows 10. Respond only in json format\"\n",
    "    user_prompt = f\"Given the icons information only return id of the icon in json format like {{\\\"id\\\" : \\\"8\\\"}} which needs to be clicked to complete this task {task}. Here is the icons information : {parsed_content_list}\"\n",
    "    icon_id = LLM(api,user_prompt,system_prompt=system_prompt,max_new_token=32)\n",
    "    print(icon_id)\n",
    "    icon_id = int(icon_id[\"id\"])\n",
    "\n",
    "    return icon_id\n",
    "    \n",
    "def Click_Icon(label_coordinates,icon_id):\n",
    "    image = Image.open(screenshot_path)\n",
    "    w , h = image.size\n",
    "\n",
    "    # Convert coordinates from normalized to actual coordinates\n",
    "    icon_coordinates = label_coordinates[icon_id]\n",
    "    x1 , y1 , x2 , y2 = icon_coordinates\n",
    "    x1 , y1 , x2 , y2 = int(x1 * w) , int(y1 * h) , int(x2 * w) , int(y2 * h)\n",
    "\n",
    "\n",
    "    # Click at centre of icon \n",
    "    x = (x1+x2)//2\n",
    "    y = (y1+y2)//2\n",
    "    # pyautogui.moveTo((x1+x2)/2,(y1+y2)/2)\n",
    "    pyautogui.click(x=x,y=y,clicks=2)\n",
    "\n",
    "def Generate_Steps(task,api):\n",
    "    # task = \"open google chrome choose my university profile that is .nu.edu.pk , go to my google classroom and from side bar open calendar \"\n",
    "    template = \"\"\" Generate a structured step-by-step GUI automation plan for a given Windows 10 task.\n",
    "    Rules: \n",
    "    1.Ensure steps logically follow the required task and flow and no illogical step.\n",
    "    2.Each action should be precise and achievable through GUI automation (Mouse click or keyboard input).\n",
    "    3.Should work for any general Windows 10 GUI task. \n",
    "    4.Only return actions that can be peformed using clicks by the bot.\n",
    "    Output Format: \n",
    "    { 'steps' :[{ 'action' : 'current action' } , {'action' : 'current action' }]}\n",
    "    \"\"\"\n",
    "    system_prompt = \"You are an excellent GUI Automation Bot that work on windows 10. Respond only in json format\"\n",
    "    user_prompt = template + f\"Here is the Task return a step by step plan according to above mentioned details : {task}\"\n",
    "    response = LLM(groq_api,user_prompt,model=\"llama-3.3-70b-versatile\",system_prompt=system_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "984db2d4-51c2-4f6f-a37d-8026412cc964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-03 20:40:53,699] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': [{'action': 'Double click on Google Chrome icon on the desktop'}, {'action': 'Click on the Muhammad Ahmad profile'}, {'action': 'Click on the Google Classroom icon'}, {'action': 'Click on the Internet of Things classroom'}]}\n",
      "{'action': 'Double click on Google Chrome icon on the desktop'}\n",
      "\n",
      "0: 384x640 59 icons, 953.5ms\n",
      "Speed: 11.0ms preprocess, 953.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "len(filtered_boxes): 64 32\n",
      "Uncached Icons = 0\n",
      "{'id': '14'}\n",
      "{'action': 'Click on the Muhammad Ahmad profile'}\n",
      "\n",
      "0: 384x640 67 icons, 1846.1ms\n",
      "Speed: 9.0ms preprocess, 1846.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "len(filtered_boxes): 74 37\n",
      "Uncached Icons = 1\n",
      "Time to get parsed content: 15.22726845741272\n",
      "{'id': '11'}\n",
      "{'action': 'Click on the Google Classroom icon'}\n",
      "\n",
      "0: 384x640 74 icons, 1843.1ms\n",
      "Speed: 8.0ms preprocess, 1843.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "len(filtered_boxes): 88 33\n",
      "Uncached Icons = 8\n",
      "Time to get parsed content: 112.75342202186584\n",
      "{'id': '1'}\n",
      "{'action': 'Click on the Internet of Things classroom'}\n",
      "\n",
      "0: 384x640 71 icons, 1865.0ms\n",
      "Speed: 9.0ms preprocess, 1865.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "len(filtered_boxes): 88 31\n",
      "Uncached Icons = 2\n",
      "Time to get parsed content: 28.63740587234497\n",
      "{'id': '26'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "    \n",
    "    # Initialize llm\n",
    "    load_dotenv()  # Load environment variables from .env file\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    groq_api = Groq(api_key=GROQ_API_KEY,)\n",
    "\n",
    "    # Initialize Models\n",
    "    resnet_path = \"resnet50.pt\"\n",
    "    yolo_path = \"weights/icon_detect/model.pt\"\n",
    "    florence_path = \"weights/icon_caption_florence\"\n",
    "\n",
    "    resnet_model = load_resnet_model(resnet_path)\n",
    "    yolo_model = load_yolo_model(yolo_path)\n",
    "    florence_model , florence_processor = load_florence_model(florence_path)\n",
    "    easyocr_reader , paddle_ocr = load_ocr()\n",
    "\n",
    "    # Enable mutithreading \n",
    "    num_cores = os.cpu_count()\n",
    "    torch.set_num_threads(num_cores)\n",
    "\n",
    "    \n",
    "    task = 'currently iam on desktop which have google chrome icon , open google chrome , google chrome will open you will see two profiles choose Muhammad Ahmad profile , go to google classroom icon is alredy in shortcut so when you will open chrome you will click on classroom icon , after that go to internet of things classroom '\n",
    "    steps = Generate_Steps(task,groq_api)\n",
    "    print(steps)\n",
    "    # encoded_image = None\n",
    "   # Go to Desktop\n",
    "    pyautogui.hotkey('win', 'd')\n",
    "    \n",
    "    count = 0\n",
    "    for step in steps['steps']:\n",
    "        print(step)\n",
    "        sub_task = step['action']\n",
    "        # Capture ScreenShot\n",
    "        screenshot_path = Capture_ScreenShot()\n",
    "        \n",
    "        # Parse ScreenShot\n",
    "        icon_coordinates , icon_descriptions = get_parsed_icons_captions(screenshot_path,florence_model,florence_processor,yolo_model,paddle_ocr,easyocr_reader,resnet_model)\n",
    "        \n",
    "        # Select icon\n",
    "        icon_id = Icon_Selection(groq_api,sub_task,icon_descriptions)\n",
    "        \n",
    "        # Click icon\n",
    "        Click_Icon(icon_coordinates,icon_id)\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068a44e-fc9f-434a-aa70-9cf21105ea9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
